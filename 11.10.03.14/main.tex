\documentclass[journal,12pt,twocolumn]{IEEEtran}
\usepackage{setspace}
\usepackage{gensymb}
\singlespacing
\usepackage[cmex10]{amsmath}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{txfonts}
\usepackage{stfloats}
\usepackage{bm}
\usepackage{cite}
\usepackage{cases}
\usepackage{subfig}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{circuitikz}
\usepackage{verbatim}
\usepackage[breaklinks=true]{hyperref}
\usepackage{tkz-euclide} % loads  TikZ and tkz-base
\usepackage{listings}
\usepackage{color}    
\usepackage{array}    
\usepackage{longtable}
\usepackage{calc}     
\usepackage{multirow} 
\usepackage{hhline}   
\usepackage{ifthen}   
\usepackage{lscape}     
\usepackage{chngcntr}
\DeclareMathOperator*{\Res}{Res}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\renewcommand\thesectiondis{\arabic{section}}
\renewcommand\thesubsectiondis{\thesectiondis.\arabic{subsection}}
\renewcommand\thesubsubsectiondis{\thesubsectiondis.\arabic{subsubsection}}
\renewcommand\thetable{\arabic{table}}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\def\inputGnumericTable{}                                 %%

\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}
%\lstset{
%language=tex,
%frame=single, 
%breaklines=true
%}

\begin{document}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[section]
\newtheorem{definition}[problem]{Definition}
\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\newcommand{\define}{\stackrel{\triangle}{=}}
\bibliographystyle{IEEEtran}
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\left\vert#1\right\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}} 
\providecommand{\norm}[1]{\left\lVert#1\right\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E\left[ #1 \right]}
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
\providecommand{\system}[1]{\overset{\mathcal{#1}}{ \longleftrightarrow}}
\newcommand{\solution}{\noindent \textbf{Solution: }}
\newcommand{\cosec}{\,\text{cosec}\,}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\newcommand{\mydet}[1]{\ensuremath{\begin{vmatrix}#1\end{vmatrix}}}
\let\vec\mathbf
\def\putbox#1#2#3{\makebox[0in][l]{\makebox[#1][l]{}\raisebox{\baselineskip}[0in][0in]{\raisebox{#2}[0in][0in]{#3}}}}
     \def\rightbox#1{\makebox[0in][r]{#1}}
     \def\centbox#1{\makebox[0in]{#1}}
     \def\topbox#1{\raisebox{-\baselineskip}[0in][0in]{#1}}
     \def\midbox#1{\raisebox{-0.5\baselineskip}[0in][0in]{#1}}

\vspace{3cm}
\title{Straight Lines Assignment}
\author{Gautam Singh}
\maketitle
\bigskip

\begin{abstract}
    This document contains the solution to Question 4 of Exercise 2 in Chapter
    10 of the class 11 NCERT textbook.
\end{abstract}

\begin{enumerate}
    \item Find the coordinates of the foot of perpendicular from the point 
    \begin{align}
        \vec{P} = \myvec{-1\\3}
        \label{eq:P-def}
    \end{align}
    to the line 
    \begin{align}
        \myvec{3&-4}\vec{x} = 16
        \label{eq:line}
    \end{align}

    \solution We present three methods to solve this problem.
    \begin{enumerate}
        \item \textit{Using convex functions.} Any point on \eqref{eq:line}
        is clearly of the form
        \begin{align}
            \vec{Q} = \myvec{0\\-4} + \lambda\myvec{4&3}
            \label{eq:Q-def}
        \end{align}
        where $\lambda \in \mathbb{R}$. Thus, $PQ$ becomes a function of $\lambda$,
        as shown in \eqref{eq:dist-lambda}.
        \begin{align}
            \norm{\vec{P}-\vec{Q}}^2 &= \norm{\myvec{4\lambda+1\\3\lambda-7}}^2 \\
                                     &= 25\lambda^2-34\lambda+50 = f(\lambda)
                                     \label{eq:dist-lambda}
        \end{align}
        Since the coefficient of $\lambda^2$ in $f(\lambda)$ is positive, it
        follows that $f(\lambda)$ is convex. Hence, the minima is achieved at
        \begin{align}
            f'(\lambda) = 50\lambda - 34 &= 0 \\
            \implies \lambda_m = \frac{17}{25}
            \label{eq:lambda-min}
        \end{align}
        Thus, substituting into \eqref{eq:Q-def}, we get
        \begin{align}
            \vec{Q_m} = \frac{1}{25}\myvec{68\\-49}
            \label{eq:Q-sol}
        \end{align}

        \item \textit{Using gradient descent.} Since \eqref{eq:dist-lambda} is
        convex, we use the gradient descent function on $\lambda$ to converge at
        the minimum of $f\brak{\lambda}$.
        \begin{align}
            \lambda_{n+1} &= \lambda_n - \alpha f'\brak{\lambda_n} \\
                          &= \brak{1-50\alpha}\lambda_n + 34\alpha
                          \label{eq:diff-eqn}
        \end{align}
        Taking the one-sided $Z$-transform on both sides of \eqref{eq:diff-eqn},
        \begin{align}
            z\Lambda\brak{z} &= \brak{1-50\alpha}\Lambda\brak{z} + \frac{34\alpha}{1-z^{-1}} \\
            \Lambda\brak{z} &= \frac{34\alpha z^{-1}}{\brak{1- z^{-1}}\brak{1 - \brak{1-50\alpha}z^{-1}}} \label{eq:roc} \\
                                     &= \frac{17}{25}\brak{\frac{1}{1-\brak{1-50\alpha}z^{-1}}-\frac{1}{1-z^{-1}}} \\
                                     &= \frac{17}{25}\sum_{k=0}^{\infty}\brak{1-\brak{1-50\alpha}^k}z^{-k}
                                     \label{eq:lambda-z-trans}
        \end{align}
        From \eqref{eq:roc}, the ROC is
        \begin{align}
            \abs{z} &> \max\cbrak{1,1-50\alpha} \\
            \implies 0 &< 1 - 50\alpha < 1 \\
            \implies \alpha &\in \brak{0,0.02}
            \label{eq:alpha-constr}
        \end{align}
        Thus, if $\alpha > 0$, then from \eqref{eq:lambda-z-trans} and \eqref{eq:lambda-min}
        \begin{align}
            \lim_{n\to\infty}\lambda_n &= \lim_{n\to\infty}\frac{17}{25}\brak{1-\brak{1-50\alpha}^n} \\
                                       &= \frac{17}{25} = \lambda_m
                                       \label{eq:conv}
        \end{align}
        We select the following parameters to arrive at the optimal $\lambda_m$,
        where $N$ is the number of iterations and $\epsilon$ is the convergence 
        limit. The gradient descent is demonstrated in Fig. \ref{fig:grad-desc},
        plotted by the Python code \texttt{codes/grad\_desc.py}. The relevant
        parameters are shown in Table \ref{tab:param}.
        \begin{table}[!ht]
            \centering
            \input{tables/11.10.03.14_1.tex}
            \caption{Parameters for Gradient Descent}
            \label{tab:param}
        \end{table}

        \begin{figure}[!ht]
            \centering
            \includegraphics[width=\columnwidth]{figs/grad_desc.png}
            \caption{Gradient descent to get the optimal $\lambda$.}
            \label{fig:grad-desc}
        \end{figure}

        \item \textit{Using Lagrange Multipliers.} We rewrite the problem as
        \begin{align}
            \min_{\vec{x}} h\brak{\vec{x}} &\triangleq \norm{\vec{x}-\vec{P}}^2 \\
            \textrm{s.t. } g\brak{\vec{x}} &\triangleq \vec{n}^\top\vec{x} - c = 0
            \label{eq:lag-opt}
        \end{align}
        Define
        \begin{align}
            C\brak{\vec{x},\lambda} &= h\brak{\vec{x}} - \lambda g\brak{\vec{x}}
            \label{eq:C-def}
        \end{align}
        and note that
        \begin{align}
            \nabla h\brak{\vec{x}} &= 2\brak{\vec{x}-\vec{P}} \\
            \nabla g\brak{\vec{x}} &= \vec{n}
            \label{eq:diff-gh}
        \end{align}
        We are required to find $\lambda \in \mathbb{R}$ such that
        \begin{align}
            \nabla C\brak{\vec{x},\lambda} &= 0 \\
            \implies 2\brak{\vec{x}-\vec{P}} - \lambda\vec{n} &= 0
            \label{eq:x-lambda}
        \end{align}
        However, $\vec{x}$ lies on the line \eqref{eq:line}. Thus, from
        \eqref{eq:x-lambda},
        \begin{align}
            \vec{n}^\top\brak{\frac{\lambda}{2}\vec{n}+\vec{P}} - c &= 0 \\
            \implies \frac{25\lambda}{2} - 15 - 16 &= 0 \\
            \implies \lambda = \frac{62}{25}
            \label{eq:lambda-opt}
        \end{align}
        Substituting \eqref{eq:lambda-opt} in \eqref{eq:x-lambda},
        \begin{align}
            \vec{x_m} &= \myvec{-1\\3} + \frac{31}{25}\myvec{3\\-4} \\
                    &= \frac{1}{25}\myvec{68\\-49}
                    \label{eq:x-sol-lag}
        \end{align}
        which matches with the solutions from the above methods. To find
        $\vec{x_m}$ graphically from this method, we use constrained gradient 
        descent, with $\alpha = 0.01$. The results are shown in Fig. 
        \ref{fig:gd-lag}, plotted using the Python code 
        \texttt{codes/gd\_lagrange.py}.
        \begin{figure}[!ht]
            \centering
            \includegraphics[width=\columnwidth]{figs/gd_lagrange.png}
            \caption{Constrained gradient descent to find optimal $\vec{x_m}$.}
            \label{fig:gd-lag}
        \end{figure}
    \end{enumerate}
\end{enumerate}
\end{document}
